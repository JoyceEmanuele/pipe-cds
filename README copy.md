# computed-data-service

O computed-data-service foi criado para que diariamente tenhamos o processamento di√°rio das telemetrias dos dispositivos(no caso da Laager verificamos com a API deles), junto √† outras configura√ß√µes dos dispositivos que s√£o obtidas no API-Server, para que seja calculado algumas informa√ß√µes com intuito de salvar em um banco de dados para facilitar o uso com PowerBI.

## Funcionamento
O servi√ßo computed-data-service realiza uma opera√ß√£o di√°ria de rotina que √© acionada pontualmente √† meia-noite, processando os dados referentes ao dia anterior. Durante esse processo, o primeiro passo consiste em realizar uma requisi√ß√£o ao API-Server para obter todos os clientes armazenados no banco de produ√ß√£o. Em seguida, cada thread fica processando um cliente por vez, com os clientes sendo distribu√≠dos dinamicamente para as threads dispon√≠veis.

Para cada cliente, √© feita uma nova requisi√ß√£o ao API-Server, desta vez para obter todas as unidades desse cliente. A partir da lista de unidades obtida, √© ent√£o feita uma nova requisi√ß√£o para cada unidade, com o objetivo de coletar todas as informa√ß√µes relativas aos dispositivos presentes naquela unidade, junto √† suas configura√ß√µes para realizar os c√°lculos necess√°rios.

Ap√≥s obtermos uma lista de dispositivos da unidade, processamos simultaneamente as fun√ß√µes de processamento de cada dispositivo, com uma observa√ß√£o para o DAC que mudamos para processar at√© 5 por vez, essas mudan√ßas nos demais dispositivos e no DAC foram necess√°rias para gerar mais paralelismo e melhorar a efici√™ncia em termos de tempo de processamento. Para cada dispositivo(exce√ß√£o Laager, que consumimos uma API externa), analisamos suas telemetrias armazenadas no DynamoDB e realizamos os processamentos necess√°rios.

Por fim, o processamento da disponibilidade de todos os dispositivos daquela unidade √© o √∫ltimo c√°lculo a ser realizado antes de avan√ßar para a pr√≥xima unidade.

## Processamento de dados de energia
Atualmente, temos uma l√≥gica que preenche buracos de hist√≥rico de consumo dos medidores de energia. 


Primeiro, preenchemos o consumo de cada dispositivo por hora, pegando o array de telemetrias de cada hora, onde o consumo dessa hora ser√° -> √∫ltima hora da telemetria.en_at_tri - primeira hora da telemetria.en_at_tri e se eu tiver o array de telemetrias da hora seguinte, ser√° primeira telemetria da hora seguinte.en_at_tri - primeira telemetria da hora atual.en_at_tri.

Logo ap√≥s isso, verificamos dentro das horas de cada dia, quais s√£o as que est√£o com consumo = 0 por n√£o ter telemetrias, a identificando como uma hora sem consumo v√°lido.
Se eu encontro uma hora em que o array de telemetrias daquela hora s√≥ tem um item, e o array de telemetrias da pr√≥xima hora √© vazio, identifico essa hora como uma sem consumo v√°lido.
Se o consumo de uma hora der negativo ou maior que 1000, a identifico como uma hora sem consumo v√°lido.
Se eu encontro uma hora sem consumo v√°lido e ainda n√£o encontrei o primeiro consumo v√°lido do dia, eu n√£o alterarei os dados dessa hora, que ser√£o verificados na l√≥gica que explicarei mais abaixo.
Se eu encontro uma hora sem consumo v√°lido e j√° passei por uma hora com consumo v√°lido, ent√£o eu salvo essa posi√ß√£o da hora sem consumo em um array e continuo procurando.

Logo ap√≥s, se eu encontro uma outra hora com consumo logo ap√≥s alguma(s) hora(s) sem consumo v√°lido, eu ent√£o pego o √∫ltimo en_at_tri da hora anterior com consumo que eu encontrei e pego o primeiro en_at_tri da hora atual com consumo que eu encontrei, fa√ßo a diferen√ßa e divido pela quantidade de horas que se passaram entre elas. Ent√£o salvo para cada hora que estava entre essas duas horas com consumo, o resultado da da diferen√ßa do en_at_tri dividindo pela quantidade de horas, que resultar√° no consumo m√©dio para essas horas faltantes.

Se esse consumo que foi feito a m√©dia for menor que 0 ou maior que 1000, salvo o consumo como 0 e identifico que essa m√©dia n√£o √© um consumo v√°lido (casos de erro na telemetria de medidores).

Logo ap√≥s preencher os buracos que foram poss√≠veis preencher durante o dia, verificamos qual foi a primeira hora com consumo v√°lido daquele dia j√° processado e ent√£o pegamos qual foi o √∫ltimo hist√≥rico com consumo v√°lido para aquele circuito el√©trico, preenchendo o buraco entre dias. 

Primeiramente tentamos preencher novamente essas horas, buscando no dynamoDB(caso o dispositivo tenha ficado algum tempo offline, quando ele voltar a ter telemetrias significa que podemos ter dados pros dias anteriores com saved_data = true), fazendo o processamento novamente desse(s) dia(s) offline, verificando buraco entre horas e dias. Mas se n√£o encontrarmos dados ou o √∫ltimo consumo salvo n√£o for igual √† hora anterior do primeiro consumo v√°lido encontrado, pegamos no dynamo o array de telemetrias da √∫ltima hora de consumo v√°lido no banco e o array de telemetrias da primeira hora de consumo v√°lido que processamos no dia, com isso pego o √∫ltimo en_at_tri do array do √∫ltimo consumo v√°lido que encontrei no banco e pego o primeiro en_at_tri do primeiro consumo v√°lido encontrado do dia processado, logo fa√ßo a diferen√ßa e divido pela quantidade de horas, em seguida salvo para cada hora o resultado dessa opera√ß√£o. Com isso, preenchemos o buraco de horas sem consumo.

Da mesma forma, se esse consumo que foi feito a m√©dia for menor que 0 ou maior que 1000, salvo o consumo como 0 e identifico que essa m√©dia n√£o √© um consumo v√°lido (casos de erro na telemetria de medidores).

Obs: Descartamos telemetrias com esses valores de en_at_tri -> Null, -1, 2147483647, 1845494299, 65535

## Processamento de dados de √°gua
Atualmente, temos uma l√≥gica que preenche buracos de hist√≥rico de consumo dos medidores de √°gua. 

Para dispositivos da Laager, temos em um primeiro momento a popula√ß√£o de consumos de litro para cada hora do dia e suas valida√ß√µes. Foi reparado que podem ocorrer telemetrias com leitura negativa pelo dispositivo, retornando ou n√£o ao normal na telemetria seguinte. 

Dessa forma, podemos encontrar alguns exemplos de telemetrias em um determinado hor√°rio, segue a valida√ß√£o para cada situa√ß√£o:

- [], teremos um consumo inv√°lido por falta de telemetria, sendo um buraco a ser tratado.
- [-40 de leitura, +40 de leitura], teremos um consumo inv√°lido pois a leitura foi incongruente e voltou ao normal, sendo um buraco a ser tratado.
- [-40 de leitura], teremos um consumo inv√°lido pois tivemos um valor incongruente de leitura, sendo um buraco a ser tratado.
- [+40 de leitura, -30 leitura], teremos um consumo v√°lido e seu valor √© 10 litros.
- [-30 de leitura, +40 leitura], teremos um consumo v√°lido e seu valor √© 10 litros.
- [0], teremos um consumo v√°lido, pois a leitura demonstrou que n√£o houve acr√©scimo de consumo.
- [0, 0], teremos um consumo v√°lido, pois as leituras demonstraram que n√£o houveram acr√©scimos de consumo.
- [+40 de leitura], teremos um consumo v√°lido, pois a leitura demonstrou que houve um consumo de 40 litros.
- [+1 de leitura, +1 de leitura], teremos um consumo v√°lido, pois as leituras demonstraram que houveram um consumo de 2 litros.

Por seguinte, com a separa√ß√£o dos consumos e suas valida√ß√µes, nomearemos como "buracos" o conjunto de hor√°rios com telemetria(s) inv√°lida(s) dentre telemetrias v√°lidas em um dia. Nessa parte do tratamento validaremos essas horas inv√°lidas pegando a primeira telemetria v√°lida depois desse conjunto de telemetria(s) inv√°lida(s) e calculando a m√©dia de consumo da seguinte forma: primeiro consumo v√°lido / horas com telemetrias inv√°lidas:
Exemplo: 
- 2:00 v√°lido com consumo igual a 0
- 3:00 inv√°lido
- 4:00 inv√°lido 
- 5:00 inv√°lido
- 6:00 v√°lido com consumo igual a 40

Ap√≥s o tratamento:
- 2:00 consumo igual a 0
- 3:00 consumo igual a 10
- 4:00 consumo igual a 10 
- 5:00 consumo igual a 10
- 6:00 consumo igual a 10

Por fim, popularemos os √∫ltimos hor√°rios de consumos inv√°lidos do dia anterior (caso haja) e primeiros hor√°rios de consumos inv√°lidos no dia atual. Pra isso, manteremos a mesma l√≥gica anterior, primeiro consumo v√°lido / n√∫mero de horas de consumos inv√°lidos at√© o √∫ltimo consumo v√°lido.

Para dispositivos DMA, manteremos l√≥gicas de tratamento parecidas com de energia. Com isso, primeiro, preenchemos o consumo de cada dispositivo por hora, pegando o array de telemetrias de cada hora, onde o consumo dessa hora ser√° -> √∫ltima hora da telemetria.pulses - primeira hora da telemetria.pulses e se eu tiver o array de telemetrias da hora seguinte, ser√° primeira telemetria da hora seguinte.pulses - primeira telemetria da hora atual.pulses.

Logo ap√≥s isso, verificamos dentro das horas de cada dia, quais s√£o as que est√£o com consumo = 0 por n√£o ter telemetrias, a identificando como uma hora sem consumo v√°lido.
Se eu encontro uma hora em que o array de telemetrias daquela hora s√≥ tem um item, e o array de telemetrias da pr√≥xima hora √© vazio, identifico essa hora como uma sem consumo v√°lido.
Se o consumo de uma hora der negativo, a identifico como uma hora sem consumo v√°lido.
Se eu encontro uma hora sem consumo v√°lido e ainda n√£o encontrei o primeiro consumo v√°lido do dia, eu n√£o alterarei os dados dessa hora, que ser√£o verificados na l√≥gica que explicarei mais abaixo.
Se eu encontro uma hora sem consumo v√°lido e j√° passei por uma hora com consumo v√°lido, ent√£o eu salvo essa posi√ß√£o da hora sem consumo em um array e continuo procurando.

Logo ap√≥s, se eu encontro uma outra hora com consumo logo ap√≥s alguma(s) hora(s) sem consumo v√°lido, eu ent√£o pego o √∫ltimo pulses da hora anterior com consumo que eu encontrei e pego o primeiro pulses da hora atual com consumo que eu encontrei, fa√ßo a diferen√ßa e divido pela quantidade de horas que se passaram entre elas. Ent√£o salvo para cada hora que estava entre essas duas horas com consumo, o resultado da diferen√ßa do pulses dividindo pela quantidade de horas, que resultar√° no consumo m√©dio para essas horas faltantes.

Logo ap√≥s preencher os buracos que foram poss√≠veis preencher durante o dia, popularemos os √∫ltimos hor√°rios de consumos inv√°lidos do dia anterior (caso haja) e primeiros hor√°rios de consumos inv√°lidos no dia atual. Para isso, manteremos a mesma l√≥gica anterior, primeiro consumo v√°lido / n√∫mero de horas de consumos inv√°lidos at√© o √∫ltimo consumo v√°lido.

## Rota para popular dias anteriores
Com a introdu√ß√£o do novo servi√ßo em produ√ß√£o, surgiu a necessidade de preencher os dados para os dias anteriores √† data em que o servi√ßo come√ßou a operar. Para atender a essa demanda, foi desenvolvida uma rota dedicada para popular esses dias espec√≠ficos. Esta rota permite especificar uma data inicial e uma data final para o per√≠odo desejado.
```sh
curl -i -X POST -H "Content-Type: application/json" -d "{\"start_date\":\"2024-03-21\",\"end_date\":\"2024-03-31\"}" http://127.0.0.1:8088/script_days/all
```

## üõ†Ô∏è Ferramentas

- O projeto foi desenvolvido utilizando `Rust` como principal linguagem, sua documenta√ß√£o √© bem interessante e pode ser encontrada no pr√≥prio [site da linguagem](https://prev.rust-lang.org/pt-BR/documentation.html). 

## üíª Pr√©-requisitos

Antes de come√ßar, √© necess√°rio verificar se todos os requisitos est√£o instalados em seu computador:

### Vers√£o mais recente da linguagem Rust
O tutorial de instala√ß√£o pode ser encontrado no pr√≥prio [site da Rust](https://www.rust-lang.org/tools/install). 

### O diesel_cli deve estar instalado na maquina

```sh
cargo install diesel_cli --no-default-features --features postgres  
```

No Windows, caso continue encontre problema ao rodar o comando acima, adicione essa vari√°vel de ambiente 
```sh
PQ_LIB_DIR="C:\Program Files\PostgreSQL\vers√£o aqui\lib,
```

Agora reinicie o computador e tente novamente

### PostgreSQL

Tamb√©m pode ser necess√°rio instalar o postgreSQL, [site do postgreSQL](https://www.postgresql.org/download/)

### Timescale
O tutorial de instala√ß√£o pode ser encontrado no pr√≥rio [site do timescale](https://docs.timescale.com/self-hosted/latest/install/)

### Ap√≥s criar o database, √© necess√°rio configurar o timescale
Rode essa linha no postgreSQL.

`CREATE EXTENSION IF NOT EXISTS timescaledb;`

### Clone o reposit√≥rio
https://github.com/dielenergia/computed-data-service.git
`git clone https://github.com/dielenergia/computed-data-service.git`

### Configure as credenciais
Em um arquivo `configfile.json5` crie as credenciais seguindo o exemplo `configfile_example.json5`

### Execute as migrations

```sh
diesel migration run --database-url postgres://user:uniquepassword@localhost:3306/database
```
